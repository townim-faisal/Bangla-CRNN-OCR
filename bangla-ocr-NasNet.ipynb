{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"bangla-ocr-NasNet.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e1KzxL_BzASM","executionInfo":{"status":"ok","timestamp":1615797841790,"user_tz":-360,"elapsed":17019,"user":{"displayName":"Townim Faisal Chowdhury","photoUrl":"","userId":"17782929784728513740"}},"outputId":"31f53569-3ef6-4fe1-c74d-f0af1b63f72e"},"source":["from google.colab import drive\r\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YcsywByoy65s","executionInfo":{"status":"ok","timestamp":1615797841792,"user_tz":-360,"elapsed":1879,"user":{"displayName":"Townim Faisal Chowdhury","photoUrl":"","userId":"17782929784728513740"}},"outputId":"2d551513-ddd8-4318-9b9d-8db99f83c496"},"source":["%cd '/content/drive/MyDrive/Colab Notebooks/bilstm-ctc'"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/bilstm-ctc\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"l6CwQQr1y5uf","executionInfo":{"status":"ok","timestamp":1615797845566,"user_tz":-360,"elapsed":2676,"user":{"displayName":"Townim Faisal Chowdhury","photoUrl":"","userId":"17782929784728513740"}}},"source":["import os, sys\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from pathlib import Path\n","from collections import Counter\n","\n","import tensorflow as tf\n","# tf.config.run_functions_eagerly(True)\n","from tensorflow import keras\n","from tensorflow.keras import layers\n"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oWSoH-Dzy5uk","executionInfo":{"status":"ok","timestamp":1614692347228,"user_tz":-360,"elapsed":1087,"user":{"displayName":"Townim Faisal Chowdhury","photoUrl":"","userId":"17782929784728513740"}},"outputId":"abeca241-1c8d-4bb8-bdf0-3f539cdb0f83"},"source":["datafile = open('./Data/ICBOCR-D4/Train/Groundtruth.txt', encoding='utf8')\n","line = datafile.readline().split('@')[1].rstrip()\n","print(line, len(\"পিঞ্জরের\"))\n","line = line.encode(\"unicode-escape\").decode()\n","print(line, len(line))\n","print('প'+'ি'+'ঞ'+'্'+'জ'+'র'+'ে'+'র')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["বনের পাখির চেয়ে পিঞ্জরের পাখিটাই বেশি ছটফট করে ! সুরেন্দ্র 8\n","\\u09ac\\u09a8\\u09c7\\u09b0 \\u09aa\\u09be\\u0996\\u09bf\\u09b0 \\u099a\\u09c7\\u09df\\u09c7 \\u09aa\\u09bf\\u099e\\u09cd\\u099c\\u09b0\\u09c7\\u09b0 \\u09aa\\u09be\\u0996\\u09bf\\u099f\\u09be\\u0987 \\u09ac\\u09c7\\u09b6\\u09bf \\u099b\\u099f\\u09ab\\u099f \\u0995\\u09b0\\u09c7 ! \\u09b8\\u09c1\\u09b0\\u09c7\\u09a8\\u09cd\\u09a6\\u09cd\\u09b0 298\n","পিঞ্জরের\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3UuFx8q0y5um","executionInfo":{"status":"ok","timestamp":1615797848717,"user_tz":-360,"elapsed":1840,"user":{"displayName":"Townim Faisal Chowdhury","photoUrl":"","userId":"17782929784728513740"}},"outputId":"a3bd6b78-745b-4f03-9fca-0393c3874f5d"},"source":["train_datafile = open('./Data/ICBOCR-D4/Train/Groundtruth.txt', encoding='utf8')\n","test_datafile = open('./Data/ICBOCR-D4/Test/Groundtruth.txt', encoding='utf8')\n","train_lines = [line.rstrip() for line in train_datafile]\n","test_lines = [line.rstrip() for line in test_datafile]\n","\n","train_image_dir = \"./Data/ICBOCR-D4/Train/Line_Images/\"\n","train_image_paths = [os.path.join(train_image_dir, line.split('@')[0]) for line in train_lines]\n","train_captions = [line.split('@')[1].lstrip() for line in train_lines]\n","\n","test_image_dir = \"./Data/ICBOCR-D4/Test/Line_Images/\"\n","for i in range(len(test_lines)):\n","  try:\n","    train_captions.append(test_lines[i].split('@')[1].lstrip())\n","    train_image_paths.append(os.path.join(test_image_dir, test_lines[i].split('@')[0]))\n","  except:\n","    print(i+1, test_lines[i])\n","\n","# for caption in train_captions:\n","#   print(caption)\n","print(len(train_image_paths), len(train_captions))\n","characters = set(char for label in train_captions for char in label)\n","print(len(characters), characters)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["200 200\n","102 {'m', 'ৎ', '.', '4', 'উ', 'ঁ', 'চ', 'u', 's', 'ট', 'ঃ', 'ঞ', 'ঙ', 'n', 'ৃ', '\\u200c', 'গ', 'া', 'ি', '\"', 'জ', 't', 'হ', '৮', 'ৰ', '।', 'I', 'ভ', '—', 'এ', '়', '–', 'য', '৩', 'r', 'v', 'দ', 'f', 'ত', 'e', \"'\", 'ন', '?', '“', 'ং', 'ু', 'ঝ', 'ণ', 'আ', 'ই', 'ড়', 'i', 'g', 'ম', 'প', '৫', 'ৌ', 'শ', '-', 'ৈ', 'y', 'অ', '১', 'h', 'ঘ', 'l', '”', '২', ' ', 'খ', 'স', 'ব', '’', '০', 'ে', 'ধ', '!', 'ঠ', 'w', 'ো', '৭', '৯', 'ষ', '\\t', ',', 'য়', 'ূ', 'o', 'ফ', 'ঢ', 'ও', '্', 'থ', 'ক', 'ঔ', 'ী', 'L', 'র', 'ল', 'ড', ';', 'ছ'}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kIxkTTg7y5um","executionInfo":{"status":"ok","timestamp":1614678103092,"user_tz":-360,"elapsed":937,"user":{"displayName":"Townim Faisal Chowdhury","photoUrl":"","userId":"17782929784728513740"}},"outputId":"cde74b55-e41d-4946-e98f-e808a68bb70a"},"source":["f = open('./Dict/AllCharcaters.txt', encoding='utf-8')\n","lines = [line.rstrip().split(',')[1] for line in f]\n","lines = set(lines)\n","print(len(lines))\n","print(lines - characters)\n","print(characters-lines)\n","characters = lines.union(characters)\n","print(len(characters), characters)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["84\n","{'ৎ', '—', 'ঙ', '৬', '•', 'ঋ', '০', 'ড', 'ৌ', '\\u200d', 'ৗ', 'ঁ', 'ঐ', '॥', '\\u200c', 'ঈ', 'ঃ', 'ং', 'ৰ', 'ঊ', '৮', '়', '১', '৪', '‘', '৭', '৯', 'ঔ', '২', 'ঢ', '৩', '৫', '\\ufeff', 'ৱ', 'ৈ', 'ঢ়'}\n","{' ', '?', '!', ',', '-'}\n","89 {'?', 'া', '।', 'ঙ', 'চ', 'ু', 'আ', 'ঋ', '•', '০', 'ঝ', 'ূ', 'ঘ', '্', 'ো', 'ধ', 'য', 'ড', 'গ', 'ভ', 'অ', 'উ', 'ঐ', 'ঈ', 'ং', 'ৰ', '৮', 'প', 'স', 'খ', 'ট', '৪', '‘', 'ছ', 'ঠ', 'ষ', 'ঔ', '২', 'ঢ', 'ত', '\\ufeff', 'ৱ', 'ৈ', 'ম', 'ৎ', ' ', 'ি', '—', '৬', 'ও', 'হ', 'ক', 'ে', 'শ', 'ৌ', 'য়', 'দ', '\\u200d', 'ৗ', 'ল', 'জ', 'ঁ', 'থ', '!', 'ই', '॥', '\\u200c', '-', 'ঃ', 'ী', 'ঊ', 'ড়', 'এ', '–', '়', 'ঞ', '১', '৭', '৯', 'র', 'ৃ', '৩', 'ব', '৫', 'ন', ',', 'ঢ়', 'ণ', 'ফ'}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0EpMcw4My5un","executionInfo":{"status":"ok","timestamp":1615797850700,"user_tz":-360,"elapsed":875,"user":{"displayName":"Townim Faisal Chowdhury","photoUrl":"","userId":"17782929784728513740"}},"outputId":"eeed81d5-8e85-4b29-fda0-40644dbdfdae"},"source":["# characters= lines\n","print(\"Number of images found: \", len(train_image_paths))\n","print(\"Number of labels found: \", len(train_captions))\n","print(\"Number of unique characters: \", len(characters))\n","print(\"Characters present: \", characters)\n","\n","# Batch size for training and validation\n","batch_size = 16\n","\n","# Desired image dimensions\n","img_width = 2452#224#2452\n","img_height = 144#224#144\n","\n","# Factor by which the image is going to be downsampled\n","# by the convolutional blocks. We will be using two\n","# convolution blocks and each block will have\n","# a pooling layer which downsample the features by a factor of 2.\n","# Hence total downsampling factor would be 4.\n","downsample_factor = 4\n","\n","# Maximum length of any captcha in the dataset\n","max_length = max([len(label) for label in train_captions])\n","print(\"Maximum length: \",max_length)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Number of images found:  200\n","Number of labels found:  200\n","Number of unique characters:  102\n","Characters present:  {'m', 'ৎ', '.', '4', 'উ', 'ঁ', 'চ', 'u', 's', 'ট', 'ঃ', 'ঞ', 'ঙ', 'n', 'ৃ', '\\u200c', 'গ', 'া', 'ি', '\"', 'জ', 't', 'হ', '৮', 'ৰ', '।', 'I', 'ভ', '—', 'এ', '়', '–', 'য', '৩', 'r', 'v', 'দ', 'f', 'ত', 'e', \"'\", 'ন', '?', '“', 'ং', 'ু', 'ঝ', 'ণ', 'আ', 'ই', 'ড়', 'i', 'g', 'ম', 'প', '৫', 'ৌ', 'শ', '-', 'ৈ', 'y', 'অ', '১', 'h', 'ঘ', 'l', '”', '২', ' ', 'খ', 'স', 'ব', '’', '০', 'ে', 'ধ', '!', 'ঠ', 'w', 'ো', '৭', '৯', 'ষ', '\\t', ',', 'য়', 'ূ', 'o', 'ফ', 'ঢ', 'ও', '্', 'থ', 'ক', 'ঔ', 'ী', 'L', 'র', 'ল', 'ড', ';', 'ছ'}\n","Maximum length:  75\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9n4F5kceseeM","executionInfo":{"status":"ok","timestamp":1615797853648,"user_tz":-360,"elapsed":1073,"user":{"displayName":"Townim Faisal Chowdhury","photoUrl":"","userId":"17782929784728513740"}}},"source":["def new_py_function(func, inp, Tout, name=None):\r\n","  def wrapped_func(*flat_inp):\r\n","    reconstructed_inp = tf.nest.pack_sequence_as(inp, flat_inp,expand_composites=True)\r\n","    out = func(*reconstructed_inp)\r\n","    return tf.nest.flatten(out, expand_composites=True)\r\n","  flat_Tout = tf.nest.flatten(Tout, expand_composites=True)\r\n","  flat_out = tf.py_function(\r\n","      func=wrapped_func, \r\n","      inp=tf.nest.flatten(inp, expand_composites=True),\r\n","      Tout=[_tensor_spec_to_dtype(v) for v in flat_Tout],\r\n","      name=name)\r\n","  spec_out = tf.nest.map_structure(_dtype_to_tensor_spec, Tout, \r\n","                                   expand_composites=True)\r\n","  out = tf.nest.pack_sequence_as(spec_out, flat_out, expand_composites=True)\r\n","  return out\r\n","\r\n","def _dtype_to_tensor_spec(v):\r\n","  return tf.TensorSpec(None, v) if isinstance(v, tf.dtypes.DType) else v\r\n","\r\n","def _tensor_spec_to_dtype(v):\r\n","  return v.dtype if isinstance(v, tf.TensorSpec) else v"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"6yNv88sMhBxN","executionInfo":{"status":"ok","timestamp":1615797860337,"user_tz":-360,"elapsed":6484,"user":{"displayName":"Townim Faisal Chowdhury","photoUrl":"","userId":"17782929784728513740"}}},"source":["# Mapping characters to integers\n","char_to_num = layers.experimental.preprocessing.StringLookup(\n","    vocabulary=list(characters), num_oov_indices=0, mask_token=''\n",")\n","\n","# Mapping integers back to original characters\n","num_to_char = layers.experimental.preprocessing.StringLookup(\n","    vocabulary=char_to_num.get_vocabulary(), mask_token=None, invert=True\n",")\n","\n","def label_to_tensor(st):\n","    f_list = list(characters)\n","    f_list.sort()\n","    st_list = []\n","    for s in st:\n","        s_index = f_list.index(s)\n","        st_list.append(s_index)\n","    return tf.convert_to_tensor(st_list, dtype=tf.float32)\n","\n","def split_data(images, labels, train_size=0.9, shuffle=True):\n","    # 1. Get the total size of the dataset\n","    size = len(images)\n","    # 2. Make an indices array and shuffle it, if required\n","    indices = np.arange(size)\n","    if shuffle:\n","        np.random.shuffle(indices)\n","    # 3. Get the size of training samples\n","    train_samples = int(size * train_size)\n","    # 4. Split data into training and validation sets\n","    x_train, y_train = images[indices[:train_samples]], labels[indices[:train_samples]]\n","    x_valid, y_valid = images[indices[train_samples:]], labels[indices[train_samples:]]\n","    return x_train, x_valid, y_train, y_valid\n","\n","\n","# Splitting data into training and validation sets\n","x_train, x_valid, y_train, y_valid = split_data(np.array(train_image_paths), np.array(train_captions))\n","\n","\n","def encode_single_sample(img_path, label):\n","    # 1. Read image\n","    img = tf.io.read_file(img_path)\n","    # 2. Decode and convert to grayscale\n","    img = tf.io.decode_jpeg(img, channels=3)\n","    # 3. Convert to float32 in [0, 1] range\n","    img = tf.image.convert_image_dtype(img, tf.float32)\n","    # 4. Resize to the desired size\n","    img = tf.image.resize(img, [img_height, img_width])\n","    img = tf.image.per_image_standardization(img) # normalize data\n","    # 5. Transpose the image because we want the time dimension to correspond to the width of the image.\n","    img = tf.transpose(img, perm=[1, 0, 2])\n","    # 6. Map the characters in label to numbers\n","    label = char_to_num(tf.strings.unicode_split(label, input_encoding=\"UTF-8\"))\n","    # label = label.numpy()\n","    label = tf.keras.preprocessing.sequence.pad_sequences([label.numpy()], maxlen=max_length, padding='post').squeeze()\n","    # 7. Return a dict as our model is expecting two inputs\n","    return {\"image\": img, \"label\": label}\n","\n","def pad_map_fn(img_path, label):\n","    return new_py_function(encode_single_sample, inp=(img_path, label), Tout=({\"image\": tf.float32, \"label\": tf.int32}))"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"nLE-Vp-7AeAe"},"source":["sample_train_x, sample_train_y = [], []\r\n","for i in range(len(x_train)):\r\n","  sample = encode_single_sample(x_train[i], y_train[i])\r\n","  sample_train_x.append(np.asarray(sample['image']))\r\n","  label = np.asarray(sample['label'])\r\n","  label = np.expand_dims(label, -1)\r\n","  sample_train_y.append(label)\r\n","sample_train_x = np.asarray(sample_train_x)/255.0\r\n","sample_train_y = np.asarray(sample_train_y)\r\n","sample_train_y = np.expand_dims(sample_train_y, -1)\r\n","\r\n","print(sample_train_x.shape)\r\n","print(sample_train_y.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lDFgzzLzhRue"},"source":["y_train"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nlKmv6cdy5uo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615797864942,"user_tz":-360,"elapsed":7768,"user":{"displayName":"Townim Faisal Chowdhury","photoUrl":"","userId":"17782929784728513740"}},"outputId":"d26daca8-29d1-4149-89c3-fa86d236c778"},"source":["batch_size = 16\n","train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n","train_dataset = train_dataset.map(\n","        pad_map_fn, num_parallel_calls=tf.data.experimental.AUTOTUNE\n","    ).batch(batch_size)#.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n","\n","validation_dataset = tf.data.Dataset.from_tensor_slices((x_valid, y_valid))\n","validation_dataset = validation_dataset.map(\n","        pad_map_fn, num_parallel_calls=tf.data.experimental.AUTOTUNE\n","    ).batch(batch_size)\n","\n","dataset = train_dataset.take(1)\n","# list(dataset.as_numpy_iterator())\n","a = list(dataset.as_numpy_iterator())\n","for a in list(dataset.as_numpy_iterator()):\n","  print(a['image'].shape, a['label'].shape)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["(16, 2452, 144, 3) (16, 75)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FtVyh4ZOy5uo","executionInfo":{"status":"ok","timestamp":1615455887011,"user_tz":-360,"elapsed":861,"user":{"displayName":"Townim Faisal Chowdhury","photoUrl":"","userId":"17782929784728513740"}},"outputId":"f30d06c7-6d8c-454a-a189-238fc7dac703"},"source":["# dataset = train_dataset.take(1)\r\n","# # list(dataset.as_numpy_iterator())\r\n","# a = list(dataset.as_numpy_iterator())\r\n","# a[0]['image'].shape, a[0]['label'].shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((1, 2452, 144, 1), (1, 51))"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"UGTSQr_utfRp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615541261369,"user_tz":-360,"elapsed":857,"user":{"displayName":"Townim Faisal Chowdhury","photoUrl":"","userId":"17782929784728513740"}},"outputId":"321dfbb4-cabe-41c1-b390-eed1b74fdc77"},"source":["# ragged tensor\r\n","batch_size = 16\r\n","train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\r\n","train_dataset = train_dataset.map(\r\n","        encode_single_sample, num_parallel_calls=tf.data.experimental.AUTOTUNE\r\n","    ).apply(tf.data.experimental.dense_to_ragged_batch(batch_size=batch_size))\r\n","\r\n","\r\n","validation_dataset = tf.data.Dataset.from_tensor_slices((x_valid, y_valid))\r\n","validation_dataset = validation_dataset.map(\r\n","        encode_single_sample, num_parallel_calls=tf.data.experimental.AUTOTUNE\r\n","    ).apply(tf.data.experimental.dense_to_ragged_batch(batch_size=batch_size))\r\n","\r\n","dataset = train_dataset.take(1)\r\n","for a in list(dataset.as_numpy_iterator()):\r\n","  print(a['image'].shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(16, 2452, 144, 1)\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/ragged/ragged_tensor.py:2012: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  return np.array(rows)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"kHKp3EwCy5up"},"source":["plt.rc('font')\n","for batch in train_dataset.take(1):\n","    images = batch[\"image\"]\n","    labels = batch[\"label\"]\n","    print(labels)\n","    for i in range(1):\n","        img = (images[i] * 255).numpy().astype(\"uint8\")\n","        print(img.shape) # (200, 50, 1)\n","        label = tf.strings.reduce_join(num_to_char(labels[i])).numpy().decode()\n","        plt.imshow(img[:, :, 0].T, cmap=\"gray\")\n","        plt.title(label)\n","        plt.axis(\"off\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ocAzBnSzzRKD","executionInfo":{"status":"ok","timestamp":1614679263461,"user_tz":-360,"elapsed":983,"user":{"displayName":"Townim Faisal Chowdhury","photoUrl":"","userId":"17782929784728513740"}},"outputId":"a1fd7471-d8b1-42fe-c42c-783e789acbc9"},"source":["###### TEST EXAMPLE\r\n","paragraph1 = np.random.random((20, 10, 50)).astype(np.float32)\r\n","paragraph2 = np.random.random((20, 10, 50)).astype(np.float32)\r\n","paragraph3 = np.random.random((20, 10, 50)).astype(np.float32)\r\n","\r\n","lstm_layer = layers.Bidirectional(layers.LSTM(512, return_sequences=True, dropout=0.25))\r\n","linear_layer = layers.Dense(512, activation=\"relu\", name=\"dense1\")\r\n","output = lstm_layer(paragraph1)\r\n","output = lstm_layer(paragraph2)\r\n","output = lstm_layer(paragraph3)\r\n","print(paragraph1.shape, output.shape, linear_layer(paragraph1).shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(20, 10, 50) (20, 10, 1024) (20, 10, 512)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sQNyWJVay5up","executionInfo":{"status":"ok","timestamp":1615798128604,"user_tz":-360,"elapsed":7948,"user":{"displayName":"Townim Faisal Chowdhury","photoUrl":"","userId":"17782929784728513740"}},"outputId":"0a6284ac-b3a5-407d-c057-789f05c63d4b"},"source":["class CTCLayer(layers.Layer):\n","    def __init__(self, name=None):\n","        super().__init__(name=name)\n","        self.loss_fn = keras.backend.ctc_batch_cost\n","\n","    def call(self, y_true, y_pred):\n","        # Compute the training-time loss value and add it to the layer using `self.add_loss()`.\n","        batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n","        input_length =  tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n","        label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n","        # print(y_true.shape, y_pred.shape)\n","        # batch_len =  nrows(y_true, 'int64')\n","        # input_length = y_pred.uniform_row_length\n","        # label_length = y_true.uniform_row_length\n","\n","        input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n","        label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n","\n","        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n","        self.add_loss(loss)\n","\n","        # At test time, just return the computed predictions\n","        return y_pred\n","\n","    # def loss(self, y_true, y_pred):\n","    #     \"\"\"The actual loss\"\"\"\n","\n","    #     batch_labels = y_true[:, :, 0]\n","    #     label_length = y_true[:, 0, 1]\n","    #     input_length = y_true[:, 0, 2]\n","\n","    #     #reshape for the loss, add that extra dimension\n","    #     label_length = tf.expand_dims(label_length, -1)\n","    #     input_length = tf.expand_dims(input_length, -1)\n","\n","    #     # use keras backend function for the loss\n","    #     return keras.backend.ctc_batch_cost(batch_labels, y_pred, input_length, label_length)\n","\n","\n","def build_model():\n","    # Inputs to the model\n","    input_img = layers.Input(shape=(img_width, img_height, 3), name=\"image\", dtype=\"float32\")\n","    labels = layers.Input(name=\"label\", shape=(None,), dtype=\"float32\")\n","\n","    # x = tf.keras.applications.MobileNetV2(include_top=False,weights=\"imagenet\",input_tensor=input_img)(input_img)\n","    x = tf.keras.applications.NASNetMobile(include_top=False,weights=\"imagenet\",input_tensor=input_img)(input_img)\n","    \n","    # new_shape = (77, 5*1280)\n","    new_shape = (77*5, 1056)\n","\n","    # We have used two max pool with pool size and strides 2.\n","    # Hence, downsampled feature maps are 4x smaller. The number of\n","    # filters in the last layer is 64. Reshape accordingly before\n","    # passing the output to the RNN part of the model\n","    # new_shape = ((img_width // 4), (img_height // 4) * 64)\n","    x = layers.Reshape(target_shape=new_shape, name=\"reshape\")(x)\n","    # x = layers.Dense(1024, activation=\"relu\", name=\"dense1\")(x)\n","    # x = layers.Dropout(0.2)(x)\n","    x = layers.Dense(512, activation=\"relu\", name=\"dense5\")(x)\n","    x = layers.Dropout(0.2)(x)\n","    # x = layers.Dense(64, activation=\"relu\", name=\"dense2\")(x)\n","    # x = layers.Dropout(0.2)(x)\n","\n","    # RNNs\n","    x = layers.Bidirectional(layers.LSTM(256, return_sequences=True, dropout=0.25))(x)\n","    # x = layers.Bidirectional(layers.LSTM(512, return_sequences=True, dropout=0.25))(x)\n","    x = layers.Bidirectional(layers.LSTM(128, return_sequences=True, dropout=0.25))(x)\n","\n","    # Output layer\n","    x = layers.Dense(len(characters) + 2, activation=\"softmax\", name=\"dense3\")(x)\n","\n","    # Add CTC layer for calculating CTC loss at each step\n","    output = CTCLayer(name=\"ctc_loss\")(labels, x)\n","\n","    # Define the model\n","    model = keras.models.Model(\n","        inputs=[input_img, labels], outputs=output, name=\"ocr_model_v1\"\n","    )\n","    # Optimizer\n","    opt = keras.optimizers.Adam(learning_rate=1e-3, decay=1e-4)\n","    # Compile the model and return\n","    model.compile(optimizer=opt)\n","    return model\n","\n","\n","# Get the model\n","model = build_model()\n","model.summary()"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/nasnet/NASNet-mobile-no-top.h5\n","19996672/19993432 [==============================] - 0s 0us/step\n","Model: \"ocr_model_v1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","image (InputLayer)              [(None, 2452, 144, 3 0                                            \n","__________________________________________________________________________________________________\n","NASNet (Functional)             (None, 77, 5, 1056)  4269716     image[0][0]                      \n","__________________________________________________________________________________________________\n","reshape (Reshape)               (None, 385, 1056)    0           NASNet[0][0]                     \n","__________________________________________________________________________________________________\n","dense5 (Dense)                  (None, 385, 512)     541184      reshape[0][0]                    \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 385, 512)     0           dense5[0][0]                     \n","__________________________________________________________________________________________________\n","bidirectional_2 (Bidirectional) (None, 385, 512)     1574912     dropout_1[0][0]                  \n","__________________________________________________________________________________________________\n","bidirectional_3 (Bidirectional) (None, 385, 256)     656384      bidirectional_2[0][0]            \n","__________________________________________________________________________________________________\n","label (InputLayer)              [(None, None)]       0                                            \n","__________________________________________________________________________________________________\n","dense3 (Dense)                  (None, 385, 104)     26728       bidirectional_3[0][0]            \n","__________________________________________________________________________________________________\n","ctc_loss (CTCLayer)             (None, 385, 104)     0           label[0][0]                      \n","                                                                 dense3[0][0]                     \n","==================================================================================================\n","Total params: 7,068,924\n","Trainable params: 7,032,186\n","Non-trainable params: 36,738\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ooJF5EcYhBxU","executionInfo":{"status":"ok","timestamp":1615810728921,"user_tz":-360,"elapsed":12599543,"user":{"displayName":"Townim Faisal Chowdhury","photoUrl":"","userId":"17782929784728513740"}},"outputId":"58ae494f-1cbb-4876-c915-75d43eb5d619"},"source":["epochs = 500\n","early_stopping_patience = 10\n","# Add early stopping\n","early_stopping = keras.callbacks.EarlyStopping(\n","    monitor=\"val_loss\", patience=early_stopping_patience, restore_best_weights=True\n",")\n","\n","# Train the model\n","# history = model.fit(\n","#     x=[sample_train_x, sample_train_y], \n","#     y=sample_train_y, \n","#     batch_size=batch_size,\n","#     validation_split=0.1,\n","#     epochs=epochs\n","# )\n","\n","checkpoint_filepath = 'checkpoint/nasnet/cp.ckpt'\n","model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=checkpoint_filepath,\n","    save_weights_only=True,\n","    monitor='val_loss',\n","    mode='min', verbose=1,\n","    save_best_only=True)\n","\n","history = model.fit(\n","    train_dataset,\n","    validation_data=validation_dataset,\n","    epochs=epochs,\n","    callbacks=[model_checkpoint_callback]\n",")\n"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Epoch 1/500\n","12/12 [==============================] - 57s 3s/step - loss: 680.8427 - val_loss: 198.4342\n","Epoch 2/500\n","12/12 [==============================] - 25s 2s/step - loss: 243.5375 - val_loss: 190.3857\n","Epoch 3/500\n","12/12 [==============================] - 25s 2s/step - loss: 234.0953 - val_loss: 188.5249\n","Epoch 4/500\n","12/12 [==============================] - 25s 2s/step - loss: 230.9651 - val_loss: 185.2992\n","Epoch 5/500\n","12/12 [==============================] - 25s 2s/step - loss: 224.4234 - val_loss: 180.2882\n","Epoch 6/500\n","12/12 [==============================] - 25s 2s/step - loss: 211.8203 - val_loss: 202.7673\n","Epoch 7/500\n","12/12 [==============================] - 25s 2s/step - loss: 198.3959 - val_loss: 205.7002\n","Epoch 8/500\n","12/12 [==============================] - 25s 2s/step - loss: 191.9881 - val_loss: 282.6757\n","Epoch 9/500\n","12/12 [==============================] - 25s 2s/step - loss: 190.2311 - val_loss: 304.0027\n","Epoch 10/500\n","12/12 [==============================] - 25s 2s/step - loss: 188.6585 - val_loss: 266.9631\n","Epoch 11/500\n","12/12 [==============================] - 25s 2s/step - loss: 186.2466 - val_loss: 239.7723\n","Epoch 12/500\n","12/12 [==============================] - 25s 2s/step - loss: 185.1518 - val_loss: 259.3956\n","Epoch 13/500\n","12/12 [==============================] - 25s 2s/step - loss: 185.2180 - val_loss: 219.3854\n","Epoch 14/500\n","12/12 [==============================] - 25s 2s/step - loss: 184.3400 - val_loss: 172.4101\n","Epoch 15/500\n","12/12 [==============================] - 25s 2s/step - loss: 184.2679 - val_loss: 163.3491\n","Epoch 16/500\n","12/12 [==============================] - 25s 2s/step - loss: 183.9569 - val_loss: 175.5856\n","Epoch 17/500\n","12/12 [==============================] - 25s 2s/step - loss: 183.5346 - val_loss: 264.5163\n","Epoch 18/500\n","12/12 [==============================] - 25s 2s/step - loss: 182.8990 - val_loss: 227.1903\n","Epoch 19/500\n","12/12 [==============================] - 25s 2s/step - loss: 182.8190 - val_loss: 207.1981\n","Epoch 20/500\n","12/12 [==============================] - 25s 2s/step - loss: 185.5159 - val_loss: 184.3643\n","Epoch 21/500\n","12/12 [==============================] - 25s 2s/step - loss: 182.5181 - val_loss: 230.8995\n","Epoch 22/500\n","12/12 [==============================] - 25s 2s/step - loss: 181.2424 - val_loss: 214.4246\n","Epoch 23/500\n","12/12 [==============================] - 25s 2s/step - loss: 180.4333 - val_loss: 238.9155\n","Epoch 24/500\n","12/12 [==============================] - 25s 2s/step - loss: 179.3333 - val_loss: 293.1270\n","Epoch 25/500\n","12/12 [==============================] - 25s 2s/step - loss: 179.3226 - val_loss: 301.6147\n","Epoch 26/500\n","12/12 [==============================] - 25s 2s/step - loss: 178.8836 - val_loss: 329.4789\n","Epoch 27/500\n","12/12 [==============================] - 25s 2s/step - loss: 178.9604 - val_loss: 263.4081\n","Epoch 28/500\n","12/12 [==============================] - 25s 2s/step - loss: 178.5506 - val_loss: 277.0888\n","Epoch 29/500\n","12/12 [==============================] - 25s 2s/step - loss: 177.2128 - val_loss: 286.2577\n","Epoch 30/500\n","12/12 [==============================] - 25s 2s/step - loss: 176.5199 - val_loss: 255.4874\n","Epoch 31/500\n","12/12 [==============================] - 25s 2s/step - loss: 176.3503 - val_loss: 253.2179\n","Epoch 32/500\n","12/12 [==============================] - 25s 2s/step - loss: 177.6334 - val_loss: 330.6538\n","Epoch 33/500\n","12/12 [==============================] - 25s 2s/step - loss: 180.7523 - val_loss: 285.4811\n","Epoch 34/500\n","12/12 [==============================] - 25s 2s/step - loss: 180.2441 - val_loss: 274.2011\n","Epoch 35/500\n","12/12 [==============================] - 25s 2s/step - loss: 177.6648 - val_loss: 266.7996\n","Epoch 36/500\n","12/12 [==============================] - 25s 2s/step - loss: 176.5973 - val_loss: 214.5076\n","Epoch 37/500\n","12/12 [==============================] - 25s 2s/step - loss: 175.0790 - val_loss: 220.3459\n","Epoch 38/500\n","12/12 [==============================] - 25s 2s/step - loss: 173.1661 - val_loss: 240.1729\n","Epoch 39/500\n","12/12 [==============================] - 25s 2s/step - loss: 171.8164 - val_loss: 264.7862\n","Epoch 40/500\n","12/12 [==============================] - 25s 2s/step - loss: 170.2848 - val_loss: 253.6760\n","Epoch 41/500\n","12/12 [==============================] - 25s 2s/step - loss: 169.8601 - val_loss: 271.8722\n","Epoch 42/500\n","12/12 [==============================] - 25s 2s/step - loss: 171.1387 - val_loss: 271.2758\n","Epoch 43/500\n","12/12 [==============================] - 25s 2s/step - loss: 168.8790 - val_loss: 282.4536\n","Epoch 44/500\n","12/12 [==============================] - 25s 2s/step - loss: 167.9670 - val_loss: 290.0291\n","Epoch 45/500\n","12/12 [==============================] - 25s 2s/step - loss: 167.0351 - val_loss: 228.2011\n","Epoch 46/500\n","12/12 [==============================] - 25s 2s/step - loss: 165.9994 - val_loss: 233.4967\n","Epoch 47/500\n","12/12 [==============================] - 25s 2s/step - loss: 166.5257 - val_loss: 201.6427\n","Epoch 48/500\n","12/12 [==============================] - 25s 2s/step - loss: 166.4297 - val_loss: 222.2369\n","Epoch 49/500\n","12/12 [==============================] - 25s 2s/step - loss: 164.7028 - val_loss: 195.5079\n","Epoch 50/500\n","12/12 [==============================] - 25s 2s/step - loss: 163.7530 - val_loss: 185.0320\n","Epoch 51/500\n","12/12 [==============================] - 25s 2s/step - loss: 162.7081 - val_loss: 183.9884\n","Epoch 52/500\n","12/12 [==============================] - 25s 2s/step - loss: 162.3519 - val_loss: 188.0856\n","Epoch 53/500\n","12/12 [==============================] - 25s 2s/step - loss: 160.5101 - val_loss: 187.8143\n","Epoch 54/500\n","12/12 [==============================] - 25s 2s/step - loss: 159.2541 - val_loss: 201.5639\n","Epoch 55/500\n","12/12 [==============================] - 25s 2s/step - loss: 158.1182 - val_loss: 226.1719\n","Epoch 56/500\n","12/12 [==============================] - 25s 2s/step - loss: 156.5699 - val_loss: 217.8372\n","Epoch 57/500\n","12/12 [==============================] - 25s 2s/step - loss: 156.3155 - val_loss: 241.3432\n","Epoch 58/500\n","12/12 [==============================] - 25s 2s/step - loss: 156.0504 - val_loss: 266.5639\n","Epoch 59/500\n","12/12 [==============================] - 25s 2s/step - loss: 154.0179 - val_loss: 263.6910\n","Epoch 60/500\n","12/12 [==============================] - 25s 2s/step - loss: 152.4631 - val_loss: 236.4782\n","Epoch 61/500\n","12/12 [==============================] - 25s 2s/step - loss: 151.1773 - val_loss: 238.1163\n","Epoch 62/500\n","12/12 [==============================] - 25s 2s/step - loss: 151.3417 - val_loss: 282.3682\n","Epoch 63/500\n","12/12 [==============================] - 26s 2s/step - loss: 149.8531 - val_loss: 325.0530\n","Epoch 64/500\n","12/12 [==============================] - 25s 2s/step - loss: 150.3140 - val_loss: 319.2957\n","Epoch 65/500\n","12/12 [==============================] - 25s 2s/step - loss: 150.2795 - val_loss: 363.4579\n","Epoch 66/500\n","12/12 [==============================] - 25s 2s/step - loss: 154.8051 - val_loss: 308.9915\n","Epoch 67/500\n","12/12 [==============================] - 25s 2s/step - loss: 153.9141 - val_loss: 310.2402\n","Epoch 68/500\n","12/12 [==============================] - 25s 2s/step - loss: 150.3253 - val_loss: 323.1458\n","Epoch 69/500\n","12/12 [==============================] - 25s 2s/step - loss: 149.6569 - val_loss: 338.2614\n","Epoch 70/500\n","12/12 [==============================] - 25s 2s/step - loss: 146.8433 - val_loss: 356.1838\n","Epoch 71/500\n","12/12 [==============================] - 25s 2s/step - loss: 142.8067 - val_loss: 257.3737\n","Epoch 72/500\n","12/12 [==============================] - 25s 2s/step - loss: 140.6954 - val_loss: 246.6512\n","Epoch 73/500\n","12/12 [==============================] - 25s 2s/step - loss: 140.2780 - val_loss: 286.3201\n","Epoch 74/500\n","12/12 [==============================] - 25s 2s/step - loss: 138.0625 - val_loss: 249.9546\n","Epoch 75/500\n","12/12 [==============================] - 25s 2s/step - loss: 136.0840 - val_loss: 278.7091\n","Epoch 76/500\n","12/12 [==============================] - 25s 2s/step - loss: 135.0943 - val_loss: 401.1356\n","Epoch 77/500\n","12/12 [==============================] - 25s 2s/step - loss: 133.4818 - val_loss: 332.5684\n","Epoch 78/500\n","12/12 [==============================] - 25s 2s/step - loss: 130.3015 - val_loss: 308.2733\n","Epoch 79/500\n","12/12 [==============================] - 25s 2s/step - loss: 128.2093 - val_loss: 279.2805\n","Epoch 80/500\n","12/12 [==============================] - 25s 2s/step - loss: 126.8004 - val_loss: 319.7138\n","Epoch 81/500\n","12/12 [==============================] - 25s 2s/step - loss: 126.1300 - val_loss: 367.6397\n","Epoch 82/500\n","12/12 [==============================] - 25s 2s/step - loss: 122.1932 - val_loss: 406.5665\n","Epoch 83/500\n","12/12 [==============================] - 25s 2s/step - loss: 121.4533 - val_loss: 382.0150\n","Epoch 84/500\n","12/12 [==============================] - 25s 2s/step - loss: 121.4377 - val_loss: 443.8012\n","Epoch 85/500\n","12/12 [==============================] - 26s 2s/step - loss: 120.0130 - val_loss: 390.0010\n","Epoch 86/500\n","12/12 [==============================] - 25s 2s/step - loss: 117.2616 - val_loss: 401.5631\n","Epoch 87/500\n","12/12 [==============================] - 25s 2s/step - loss: 115.4245 - val_loss: 348.2406\n","Epoch 88/500\n","12/12 [==============================] - 25s 2s/step - loss: 112.0669 - val_loss: 454.5891\n","Epoch 89/500\n","12/12 [==============================] - 25s 2s/step - loss: 109.0947 - val_loss: 449.3420\n","Epoch 90/500\n","12/12 [==============================] - 25s 2s/step - loss: 109.3369 - val_loss: 503.6855\n","Epoch 91/500\n","12/12 [==============================] - 25s 2s/step - loss: 107.6386 - val_loss: 502.6673\n","Epoch 92/500\n","12/12 [==============================] - 25s 2s/step - loss: 106.6597 - val_loss: 475.2436\n","Epoch 93/500\n","12/12 [==============================] - 25s 2s/step - loss: 104.1535 - val_loss: 439.2130\n","Epoch 94/500\n","12/12 [==============================] - 25s 2s/step - loss: 102.2005 - val_loss: 509.8553\n","Epoch 95/500\n","12/12 [==============================] - 25s 2s/step - loss: 99.2443 - val_loss: 596.0638\n","Epoch 96/500\n","12/12 [==============================] - 25s 2s/step - loss: 96.5009 - val_loss: 601.6776\n","Epoch 97/500\n","12/12 [==============================] - 25s 2s/step - loss: 94.5346 - val_loss: 791.2612\n","Epoch 98/500\n","12/12 [==============================] - 25s 2s/step - loss: 92.3486 - val_loss: 747.3844\n","Epoch 99/500\n","12/12 [==============================] - 25s 2s/step - loss: 90.2398 - val_loss: 696.3293\n","Epoch 100/500\n","12/12 [==============================] - 25s 2s/step - loss: 89.6495 - val_loss: 521.1028\n","Epoch 101/500\n","12/12 [==============================] - 25s 2s/step - loss: 88.3204 - val_loss: 562.1906\n","Epoch 102/500\n","12/12 [==============================] - 25s 2s/step - loss: 86.5326 - val_loss: 593.4244\n","Epoch 103/500\n","12/12 [==============================] - 25s 2s/step - loss: 84.9818 - val_loss: 374.8487\n","Epoch 104/500\n","12/12 [==============================] - 25s 2s/step - loss: 83.2940 - val_loss: 489.2520\n","Epoch 105/500\n","12/12 [==============================] - 25s 2s/step - loss: 80.4406 - val_loss: 599.9004\n","Epoch 106/500\n","12/12 [==============================] - 25s 2s/step - loss: 78.2114 - val_loss: 613.1945\n","Epoch 107/500\n","12/12 [==============================] - 25s 2s/step - loss: 76.7346 - val_loss: 571.6492\n","Epoch 108/500\n","12/12 [==============================] - 25s 2s/step - loss: 75.5958 - val_loss: 520.3401\n","Epoch 109/500\n","12/12 [==============================] - 25s 2s/step - loss: 72.9617 - val_loss: 623.3619\n","Epoch 110/500\n","12/12 [==============================] - 25s 2s/step - loss: 70.3322 - val_loss: 601.6618\n","Epoch 111/500\n","12/12 [==============================] - 25s 2s/step - loss: 67.0927 - val_loss: 653.3917\n","Epoch 112/500\n","12/12 [==============================] - 25s 2s/step - loss: 66.3964 - val_loss: 633.1006\n","Epoch 113/500\n","12/12 [==============================] - 25s 2s/step - loss: 64.4710 - val_loss: 571.6852\n","Epoch 114/500\n","12/12 [==============================] - 25s 2s/step - loss: 62.3321 - val_loss: 642.4728\n","Epoch 115/500\n","12/12 [==============================] - 25s 2s/step - loss: 60.4825 - val_loss: 674.5250\n","Epoch 116/500\n","12/12 [==============================] - 25s 2s/step - loss: 58.3535 - val_loss: 671.3203\n","Epoch 117/500\n","12/12 [==============================] - 25s 2s/step - loss: 54.9014 - val_loss: 678.6517\n","Epoch 118/500\n","12/12 [==============================] - 25s 2s/step - loss: 54.3172 - val_loss: 575.0928\n","Epoch 119/500\n","12/12 [==============================] - 25s 2s/step - loss: 51.7179 - val_loss: 624.0065\n","Epoch 120/500\n","12/12 [==============================] - 25s 2s/step - loss: 49.1541 - val_loss: 588.4532\n","Epoch 121/500\n","12/12 [==============================] - 25s 2s/step - loss: 46.7982 - val_loss: 645.0650\n","Epoch 122/500\n","12/12 [==============================] - 25s 2s/step - loss: 43.4818 - val_loss: 660.0980\n","Epoch 123/500\n","12/12 [==============================] - 25s 2s/step - loss: 41.7273 - val_loss: 618.3329\n","Epoch 124/500\n","12/12 [==============================] - 25s 2s/step - loss: 39.2965 - val_loss: 744.3415\n","Epoch 125/500\n","12/12 [==============================] - 25s 2s/step - loss: 36.9687 - val_loss: 708.4179\n","Epoch 126/500\n","12/12 [==============================] - 25s 2s/step - loss: 35.1844 - val_loss: 747.2965\n","Epoch 127/500\n","12/12 [==============================] - 25s 2s/step - loss: 34.8370 - val_loss: 712.6714\n","Epoch 128/500\n","12/12 [==============================] - 25s 2s/step - loss: 33.1531 - val_loss: 701.3898\n","Epoch 129/500\n","12/12 [==============================] - 25s 2s/step - loss: 33.4307 - val_loss: 666.6051\n","Epoch 130/500\n","12/12 [==============================] - 25s 2s/step - loss: 33.3121 - val_loss: 725.3566\n","Epoch 131/500\n","12/12 [==============================] - 25s 2s/step - loss: 32.5432 - val_loss: 707.2289\n","Epoch 132/500\n","12/12 [==============================] - 25s 2s/step - loss: 30.9361 - val_loss: 665.5534\n","Epoch 133/500\n","12/12 [==============================] - 25s 2s/step - loss: 29.2323 - val_loss: 605.4297\n","Epoch 134/500\n","12/12 [==============================] - 25s 2s/step - loss: 27.9050 - val_loss: 765.0123\n","Epoch 135/500\n","12/12 [==============================] - 25s 2s/step - loss: 26.3366 - val_loss: 803.2262\n","Epoch 136/500\n","12/12 [==============================] - 25s 2s/step - loss: 24.9242 - val_loss: 745.9397\n","Epoch 137/500\n","12/12 [==============================] - 25s 2s/step - loss: 24.6856 - val_loss: 832.1262\n","Epoch 138/500\n","12/12 [==============================] - 25s 2s/step - loss: 22.8811 - val_loss: 891.9593\n","Epoch 139/500\n","12/12 [==============================] - 25s 2s/step - loss: 21.3220 - val_loss: 867.8104\n","Epoch 140/500\n","12/12 [==============================] - 25s 2s/step - loss: 19.3174 - val_loss: 792.8330\n","Epoch 141/500\n","12/12 [==============================] - 25s 2s/step - loss: 18.6623 - val_loss: 818.0497\n","Epoch 142/500\n","12/12 [==============================] - 25s 2s/step - loss: 17.4300 - val_loss: 835.0381\n","Epoch 143/500\n","12/12 [==============================] - 25s 2s/step - loss: 16.8289 - val_loss: 790.3079\n","Epoch 144/500\n","12/12 [==============================] - 25s 2s/step - loss: 16.1867 - val_loss: 879.6313\n","Epoch 145/500\n","12/12 [==============================] - 25s 2s/step - loss: 15.3767 - val_loss: 904.2308\n","Epoch 146/500\n","12/12 [==============================] - 25s 2s/step - loss: 14.9166 - val_loss: 849.0668\n","Epoch 147/500\n","12/12 [==============================] - 25s 2s/step - loss: 14.0630 - val_loss: 845.6395\n","Epoch 148/500\n","12/12 [==============================] - 25s 2s/step - loss: 13.5618 - val_loss: 856.6422\n","Epoch 149/500\n","12/12 [==============================] - 25s 2s/step - loss: 13.8112 - val_loss: 849.0425\n","Epoch 150/500\n","12/12 [==============================] - 26s 2s/step - loss: 12.8848 - val_loss: 869.6528\n","Epoch 151/500\n","12/12 [==============================] - 25s 2s/step - loss: 12.4909 - val_loss: 799.4793\n","Epoch 152/500\n","12/12 [==============================] - 25s 2s/step - loss: 12.1493 - val_loss: 862.8149\n","Epoch 153/500\n","12/12 [==============================] - 25s 2s/step - loss: 11.9277 - val_loss: 949.1834\n","Epoch 154/500\n","12/12 [==============================] - 25s 2s/step - loss: 11.3487 - val_loss: 909.4225\n","Epoch 155/500\n","12/12 [==============================] - 25s 2s/step - loss: 10.9143 - val_loss: 883.9728\n","Epoch 156/500\n","12/12 [==============================] - 25s 2s/step - loss: 11.0082 - val_loss: 867.2284\n","Epoch 157/500\n","12/12 [==============================] - 25s 2s/step - loss: 10.4299 - val_loss: 864.3846\n","Epoch 158/500\n","12/12 [==============================] - 25s 2s/step - loss: 10.1670 - val_loss: 842.9427\n","Epoch 159/500\n","12/12 [==============================] - 25s 2s/step - loss: 9.8307 - val_loss: 836.8422\n","Epoch 160/500\n","12/12 [==============================] - 25s 2s/step - loss: 9.2771 - val_loss: 844.3522\n","Epoch 161/500\n","12/12 [==============================] - 25s 2s/step - loss: 9.1188 - val_loss: 824.1161\n","Epoch 162/500\n","12/12 [==============================] - 25s 2s/step - loss: 8.8375 - val_loss: 832.7840\n","Epoch 163/500\n","12/12 [==============================] - 25s 2s/step - loss: 8.5385 - val_loss: 860.3221\n","Epoch 164/500\n","12/12 [==============================] - 25s 2s/step - loss: 8.2187 - val_loss: 862.3217\n","Epoch 165/500\n","12/12 [==============================] - 25s 2s/step - loss: 8.0167 - val_loss: 869.0933\n","Epoch 166/500\n","12/12 [==============================] - 25s 2s/step - loss: 7.8592 - val_loss: 865.9764\n","Epoch 167/500\n","12/12 [==============================] - 25s 2s/step - loss: 7.7140 - val_loss: 892.3841\n","Epoch 168/500\n","12/12 [==============================] - 25s 2s/step - loss: 7.4475 - val_loss: 894.1434\n","Epoch 169/500\n","12/12 [==============================] - 25s 2s/step - loss: 7.3538 - val_loss: 819.3805\n","Epoch 170/500\n","12/12 [==============================] - 26s 2s/step - loss: 7.3421 - val_loss: 868.5145\n","Epoch 171/500\n","12/12 [==============================] - 25s 2s/step - loss: 7.2115 - val_loss: 881.8324\n","Epoch 172/500\n","12/12 [==============================] - 25s 2s/step - loss: 6.9952 - val_loss: 887.4338\n","Epoch 173/500\n","12/12 [==============================] - 25s 2s/step - loss: 6.8743 - val_loss: 879.7368\n","Epoch 174/500\n","12/12 [==============================] - 25s 2s/step - loss: 6.5720 - val_loss: 839.9591\n","Epoch 175/500\n","12/12 [==============================] - 25s 2s/step - loss: 6.7938 - val_loss: 835.1907\n","Epoch 176/500\n","12/12 [==============================] - 25s 2s/step - loss: 6.5471 - val_loss: 871.5970\n","Epoch 177/500\n","12/12 [==============================] - 25s 2s/step - loss: 6.4848 - val_loss: 858.2314\n","Epoch 178/500\n","12/12 [==============================] - 25s 2s/step - loss: 6.2548 - val_loss: 824.5953\n","Epoch 179/500\n","12/12 [==============================] - 25s 2s/step - loss: 6.0619 - val_loss: 819.2921\n","Epoch 180/500\n","12/12 [==============================] - 25s 2s/step - loss: 6.0995 - val_loss: 809.1569\n","Epoch 181/500\n","12/12 [==============================] - 25s 2s/step - loss: 5.9550 - val_loss: 846.8452\n","Epoch 182/500\n","12/12 [==============================] - 25s 2s/step - loss: 5.9347 - val_loss: 829.1867\n","Epoch 183/500\n","12/12 [==============================] - 25s 2s/step - loss: 5.8334 - val_loss: 805.9152\n","Epoch 184/500\n","12/12 [==============================] - 25s 2s/step - loss: 5.7200 - val_loss: 813.2015\n","Epoch 185/500\n","12/12 [==============================] - 25s 2s/step - loss: 5.6124 - val_loss: 815.6912\n","Epoch 186/500\n","12/12 [==============================] - 25s 2s/step - loss: 5.5245 - val_loss: 820.6737\n","Epoch 187/500\n","12/12 [==============================] - 25s 2s/step - loss: 5.4654 - val_loss: 828.7420\n","Epoch 188/500\n","12/12 [==============================] - 25s 2s/step - loss: 5.2431 - val_loss: 831.8998\n","Epoch 189/500\n","12/12 [==============================] - 25s 2s/step - loss: 5.1725 - val_loss: 858.5436\n","Epoch 190/500\n","12/12 [==============================] - 25s 2s/step - loss: 5.1859 - val_loss: 853.3346\n","Epoch 191/500\n","12/12 [==============================] - 25s 2s/step - loss: 5.0715 - val_loss: 829.9244\n","Epoch 192/500\n","12/12 [==============================] - 25s 2s/step - loss: 4.9361 - val_loss: 860.9334\n","Epoch 193/500\n","12/12 [==============================] - 25s 2s/step - loss: 4.7994 - val_loss: 853.7584\n","Epoch 194/500\n","12/12 [==============================] - 25s 2s/step - loss: 4.7440 - val_loss: 849.2969\n","Epoch 195/500\n","12/12 [==============================] - 25s 2s/step - loss: 4.7216 - val_loss: 823.0458\n","Epoch 196/500\n","12/12 [==============================] - 25s 2s/step - loss: 4.7145 - val_loss: 841.7528\n","Epoch 197/500\n","12/12 [==============================] - 25s 2s/step - loss: 4.7038 - val_loss: 859.1208\n","Epoch 198/500\n","12/12 [==============================] - 25s 2s/step - loss: 4.6342 - val_loss: 841.6979\n","Epoch 199/500\n","12/12 [==============================] - 25s 2s/step - loss: 4.4971 - val_loss: 844.0449\n","Epoch 200/500\n","12/12 [==============================] - 25s 2s/step - loss: 4.4091 - val_loss: 836.0614\n","Epoch 201/500\n","12/12 [==============================] - 25s 2s/step - loss: 4.3418 - val_loss: 858.4374\n","Epoch 202/500\n","12/12 [==============================] - 25s 2s/step - loss: 4.3826 - val_loss: 861.0137\n","Epoch 203/500\n","12/12 [==============================] - 25s 2s/step - loss: 4.2258 - val_loss: 858.0109\n","Epoch 204/500\n","12/12 [==============================] - 25s 2s/step - loss: 4.1914 - val_loss: 882.8947\n","Epoch 205/500\n","12/12 [==============================] - 25s 2s/step - loss: 4.0955 - val_loss: 840.8553\n","Epoch 206/500\n","12/12 [==============================] - 25s 2s/step - loss: 4.0451 - val_loss: 846.5197\n","Epoch 207/500\n","12/12 [==============================] - 25s 2s/step - loss: 4.0233 - val_loss: 845.1144\n","Epoch 208/500\n","12/12 [==============================] - 25s 2s/step - loss: 3.9892 - val_loss: 869.1536\n","Epoch 209/500\n","12/12 [==============================] - 25s 2s/step - loss: 3.9924 - val_loss: 911.5001\n","Epoch 210/500\n","12/12 [==============================] - 25s 2s/step - loss: 4.2428 - val_loss: 863.1776\n","Epoch 211/500\n","12/12 [==============================] - 25s 2s/step - loss: 4.0093 - val_loss: 829.3654\n","Epoch 212/500\n","12/12 [==============================] - 25s 2s/step - loss: 4.0681 - val_loss: 844.7583\n","Epoch 213/500\n","12/12 [==============================] - 25s 2s/step - loss: 4.1599 - val_loss: 879.1535\n","Epoch 214/500\n","12/12 [==============================] - 25s 2s/step - loss: 4.4516 - val_loss: 883.5502\n","Epoch 215/500\n","12/12 [==============================] - 25s 2s/step - loss: 4.5476 - val_loss: 686.8903\n","Epoch 216/500\n","12/12 [==============================] - 25s 2s/step - loss: 6.7874 - val_loss: 736.6107\n","Epoch 217/500\n","12/12 [==============================] - 25s 2s/step - loss: 14.8884 - val_loss: 834.6621\n","Epoch 218/500\n","12/12 [==============================] - 25s 2s/step - loss: 46.5248 - val_loss: 641.2330\n","Epoch 219/500\n","12/12 [==============================] - 25s 2s/step - loss: 98.7028 - val_loss: 324.8904\n","Epoch 220/500\n","12/12 [==============================] - 25s 2s/step - loss: 150.9694 - val_loss: 511.0063\n","Epoch 221/500\n","12/12 [==============================] - 25s 2s/step - loss: 143.2037 - val_loss: 475.9970\n","Epoch 222/500\n","12/12 [==============================] - 25s 2s/step - loss: 130.2156 - val_loss: 273.2208\n","Epoch 223/500\n","12/12 [==============================] - 25s 2s/step - loss: 106.9480 - val_loss: 379.2813\n","Epoch 224/500\n","12/12 [==============================] - 25s 2s/step - loss: 86.4851 - val_loss: 382.8859\n","Epoch 225/500\n","12/12 [==============================] - 25s 2s/step - loss: 71.4504 - val_loss: 508.4445\n","Epoch 226/500\n","12/12 [==============================] - 25s 2s/step - loss: 60.8619 - val_loss: 482.4026\n","Epoch 227/500\n","12/12 [==============================] - 25s 2s/step - loss: 50.9282 - val_loss: 500.6002\n","Epoch 228/500\n","12/12 [==============================] - 25s 2s/step - loss: 41.0214 - val_loss: 562.0239\n","Epoch 229/500\n","12/12 [==============================] - 26s 2s/step - loss: 33.8671 - val_loss: 532.0062\n","Epoch 230/500\n","12/12 [==============================] - 25s 2s/step - loss: 28.2364 - val_loss: 444.8612\n","Epoch 231/500\n","12/12 [==============================] - 25s 2s/step - loss: 24.2017 - val_loss: 565.7886\n","Epoch 232/500\n","12/12 [==============================] - 25s 2s/step - loss: 21.8114 - val_loss: 412.0739\n","Epoch 233/500\n","12/12 [==============================] - 25s 2s/step - loss: 18.3013 - val_loss: 361.0486\n","Epoch 234/500\n","12/12 [==============================] - 25s 2s/step - loss: 16.7283 - val_loss: 579.0697\n","Epoch 235/500\n","12/12 [==============================] - 25s 2s/step - loss: 13.8447 - val_loss: 523.4926\n","Epoch 236/500\n","12/12 [==============================] - 25s 2s/step - loss: 12.1010 - val_loss: 486.0827\n","Epoch 237/500\n","12/12 [==============================] - 25s 2s/step - loss: 10.4218 - val_loss: 582.2396\n","Epoch 238/500\n","12/12 [==============================] - 25s 2s/step - loss: 8.7663 - val_loss: 555.8993\n","Epoch 239/500\n","12/12 [==============================] - 25s 2s/step - loss: 7.9821 - val_loss: 718.9548\n","Epoch 240/500\n","12/12 [==============================] - 25s 2s/step - loss: 7.0867 - val_loss: 683.1144\n","Epoch 241/500\n","12/12 [==============================] - 25s 2s/step - loss: 6.8029 - val_loss: 682.9892\n","Epoch 242/500\n","12/12 [==============================] - 25s 2s/step - loss: 6.4130 - val_loss: 680.3556\n","Epoch 243/500\n","12/12 [==============================] - 26s 2s/step - loss: 5.9295 - val_loss: 691.1569\n","Epoch 244/500\n","12/12 [==============================] - 25s 2s/step - loss: 5.6859 - val_loss: 675.8212\n","Epoch 245/500\n","12/12 [==============================] - 25s 2s/step - loss: 5.5104 - val_loss: 674.4852\n","Epoch 246/500\n","12/12 [==============================] - 25s 2s/step - loss: 5.2508 - val_loss: 686.6615\n","Epoch 247/500\n","12/12 [==============================] - 25s 2s/step - loss: 5.0185 - val_loss: 650.5388\n","Epoch 248/500\n","12/12 [==============================] - 25s 2s/step - loss: 4.8263 - val_loss: 644.2972\n","Epoch 249/500\n","12/12 [==============================] - 25s 2s/step - loss: 4.7506 - val_loss: 639.8705\n","Epoch 250/500\n","12/12 [==============================] - 25s 2s/step - loss: 4.8259 - val_loss: 604.8762\n","Epoch 251/500\n","12/12 [==============================] - 25s 2s/step - loss: 4.5628 - val_loss: 631.2961\n","Epoch 252/500\n","12/12 [==============================] - 25s 2s/step - loss: 4.3979 - val_loss: 640.1105\n","Epoch 253/500\n","12/12 [==============================] - 25s 2s/step - loss: 4.4417 - val_loss: 633.9648\n","Epoch 254/500\n","12/12 [==============================] - 25s 2s/step - loss: 4.3661 - val_loss: 620.1530\n","Epoch 255/500\n","12/12 [==============================] - 25s 2s/step - loss: 4.2443 - val_loss: 598.7324\n","Epoch 256/500\n","12/12 [==============================] - 25s 2s/step - loss: 4.1073 - val_loss: 597.3871\n","Epoch 257/500\n","12/12 [==============================] - 25s 2s/step - loss: 4.1088 - val_loss: 606.4773\n","Epoch 258/500\n","12/12 [==============================] - 25s 2s/step - loss: 4.0051 - val_loss: 636.8868\n","Epoch 259/500\n","12/12 [==============================] - 25s 2s/step - loss: 3.9437 - val_loss: 623.9493\n","Epoch 260/500\n","12/12 [==============================] - 25s 2s/step - loss: 4.0982 - val_loss: 626.1210\n","Epoch 261/500\n","12/12 [==============================] - 25s 2s/step - loss: 3.9282 - val_loss: 613.7971\n","Epoch 262/500\n","12/12 [==============================] - 25s 2s/step - loss: 3.8898 - val_loss: 618.0504\n","Epoch 263/500\n","12/12 [==============================] - 25s 2s/step - loss: 3.7985 - val_loss: 603.6383\n","Epoch 264/500\n","12/12 [==============================] - 25s 2s/step - loss: 3.7501 - val_loss: 588.5431\n","Epoch 265/500\n","12/12 [==============================] - 26s 2s/step - loss: 3.5749 - val_loss: 600.8273\n","Epoch 266/500\n","12/12 [==============================] - 25s 2s/step - loss: 3.6004 - val_loss: 601.9490\n","Epoch 267/500\n","12/12 [==============================] - 25s 2s/step - loss: 3.6792 - val_loss: 621.8131\n","Epoch 268/500\n","12/12 [==============================] - 25s 2s/step - loss: 3.8274 - val_loss: 638.5612\n","Epoch 269/500\n","12/12 [==============================] - 25s 2s/step - loss: 4.5692 - val_loss: 660.6830\n","Epoch 270/500\n","12/12 [==============================] - 25s 2s/step - loss: 4.6388 - val_loss: 622.6743\n","Epoch 271/500\n","12/12 [==============================] - 26s 2s/step - loss: 4.1573 - val_loss: 585.2028\n","Epoch 272/500\n","12/12 [==============================] - 25s 2s/step - loss: 3.7947 - val_loss: 583.1595\n","Epoch 273/500\n","12/12 [==============================] - 25s 2s/step - loss: 3.6101 - val_loss: 588.7892\n","Epoch 274/500\n","12/12 [==============================] - 25s 2s/step - loss: 3.4796 - val_loss: 606.4038\n","Epoch 275/500\n","12/12 [==============================] - 25s 2s/step - loss: 3.4074 - val_loss: 612.7552\n","Epoch 276/500\n","12/12 [==============================] - 25s 2s/step - loss: 3.3893 - val_loss: 595.6825\n","Epoch 277/500\n","12/12 [==============================] - 25s 2s/step - loss: 3.3445 - val_loss: 604.0122\n","Epoch 278/500\n","12/12 [==============================] - 25s 2s/step - loss: 3.2689 - val_loss: 602.4990\n","Epoch 279/500\n","12/12 [==============================] - 25s 2s/step - loss: 3.2822 - val_loss: 605.7751\n","Epoch 280/500\n","12/12 [==============================] - 25s 2s/step - loss: 3.2057 - val_loss: 612.7689\n","Epoch 281/500\n","12/12 [==============================] - 25s 2s/step - loss: 3.1925 - val_loss: 620.9889\n","Epoch 282/500\n","12/12 [==============================] - 25s 2s/step - loss: 3.1171 - val_loss: 606.2565\n","Epoch 283/500\n","12/12 [==============================] - 25s 2s/step - loss: 3.0934 - val_loss: 606.0285\n","Epoch 284/500\n","12/12 [==============================] - 25s 2s/step - loss: 3.0627 - val_loss: 612.7484\n","Epoch 285/500\n","12/12 [==============================] - 25s 2s/step - loss: 3.0017 - val_loss: 610.5052\n","Epoch 286/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.9728 - val_loss: 599.8140\n","Epoch 287/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.9297 - val_loss: 596.5981\n","Epoch 288/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.9915 - val_loss: 589.9994\n","Epoch 289/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.8922 - val_loss: 585.8732\n","Epoch 290/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.9197 - val_loss: 601.9034\n","Epoch 291/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.9345 - val_loss: 598.4026\n","Epoch 292/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.8346 - val_loss: 604.8268\n","Epoch 293/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.8510 - val_loss: 621.2731\n","Epoch 294/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.8026 - val_loss: 617.6793\n","Epoch 295/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.8417 - val_loss: 605.4352\n","Epoch 296/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.8320 - val_loss: 622.8875\n","Epoch 297/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.8972 - val_loss: 607.7452\n","Epoch 298/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.8958 - val_loss: 619.8801\n","Epoch 299/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.8456 - val_loss: 623.8626\n","Epoch 300/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.9542 - val_loss: 623.6317\n","Epoch 301/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.7869 - val_loss: 612.6265\n","Epoch 302/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.7532 - val_loss: 598.6010\n","Epoch 303/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.7037 - val_loss: 600.4003\n","Epoch 304/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.6657 - val_loss: 592.7643\n","Epoch 305/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.6386 - val_loss: 590.1816\n","Epoch 306/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.6405 - val_loss: 586.5663\n","Epoch 307/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.5977 - val_loss: 579.0215\n","Epoch 308/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.6060 - val_loss: 576.7145\n","Epoch 309/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.5918 - val_loss: 566.0759\n","Epoch 310/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.6312 - val_loss: 566.8075\n","Epoch 311/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.5903 - val_loss: 559.9963\n","Epoch 312/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.5803 - val_loss: 547.6729\n","Epoch 313/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.6005 - val_loss: 540.0988\n","Epoch 314/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.5520 - val_loss: 536.3026\n","Epoch 315/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.5118 - val_loss: 529.6761\n","Epoch 316/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.5323 - val_loss: 536.0177\n","Epoch 317/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.5041 - val_loss: 542.4115\n","Epoch 318/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.4998 - val_loss: 538.6224\n","Epoch 319/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.4674 - val_loss: 528.8183\n","Epoch 320/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.4935 - val_loss: 526.9538\n","Epoch 321/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.4738 - val_loss: 532.9513\n","Epoch 322/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.4646 - val_loss: 536.2393\n","Epoch 323/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.4335 - val_loss: 532.6240\n","Epoch 324/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.5097 - val_loss: 536.1976\n","Epoch 325/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.4750 - val_loss: 527.4111\n","Epoch 326/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.4267 - val_loss: 524.6395\n","Epoch 327/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.4314 - val_loss: 530.7228\n","Epoch 328/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.4127 - val_loss: 528.4470\n","Epoch 329/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.3881 - val_loss: 530.6957\n","Epoch 330/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.4087 - val_loss: 515.6283\n","Epoch 331/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.4059 - val_loss: 505.7151\n","Epoch 332/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.3665 - val_loss: 499.5157\n","Epoch 333/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.3750 - val_loss: 496.3911\n","Epoch 334/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.3717 - val_loss: 500.3834\n","Epoch 335/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.3681 - val_loss: 491.9921\n","Epoch 336/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.3395 - val_loss: 488.6082\n","Epoch 337/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.3455 - val_loss: 477.5405\n","Epoch 338/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.3373 - val_loss: 473.5975\n","Epoch 339/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.3169 - val_loss: 470.1805\n","Epoch 340/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.3121 - val_loss: 475.9616\n","Epoch 341/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.3205 - val_loss: 485.7663\n","Epoch 342/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.3013 - val_loss: 472.8227\n","Epoch 343/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.2940 - val_loss: 473.0389\n","Epoch 344/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.2739 - val_loss: 463.7899\n","Epoch 345/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.2867 - val_loss: 458.8264\n","Epoch 346/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.2722 - val_loss: 458.8034\n","Epoch 347/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.2452 - val_loss: 459.1349\n","Epoch 348/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.2746 - val_loss: 458.6890\n","Epoch 349/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.2375 - val_loss: 460.3814\n","Epoch 350/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.2362 - val_loss: 458.2012\n","Epoch 351/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.2039 - val_loss: 459.4398\n","Epoch 352/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.1949 - val_loss: 456.2253\n","Epoch 353/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.2096 - val_loss: 425.8784\n","Epoch 354/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.5534 - val_loss: 459.3019\n","Epoch 355/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.4664 - val_loss: 447.6448\n","Epoch 356/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.4161 - val_loss: 458.6563\n","Epoch 357/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.3583 - val_loss: 440.4934\n","Epoch 358/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.9903 - val_loss: 471.8073\n","Epoch 359/500\n","12/12 [==============================] - 25s 2s/step - loss: 4.2809 - val_loss: 402.5418\n","Epoch 360/500\n","12/12 [==============================] - 25s 2s/step - loss: 8.8541 - val_loss: 324.1677\n","Epoch 361/500\n","12/12 [==============================] - 26s 2s/step - loss: 23.7903 - val_loss: 439.3857\n","Epoch 362/500\n","12/12 [==============================] - 25s 2s/step - loss: 37.2660 - val_loss: 406.0419\n","Epoch 363/500\n","12/12 [==============================] - 25s 2s/step - loss: 44.8688 - val_loss: 353.6773\n","Epoch 364/500\n","12/12 [==============================] - 25s 2s/step - loss: 48.8256 - val_loss: 401.7865\n","Epoch 365/500\n","12/12 [==============================] - 25s 2s/step - loss: 55.4963 - val_loss: 504.7760\n","Epoch 366/500\n","12/12 [==============================] - 25s 2s/step - loss: 54.5618 - val_loss: 402.5079\n","Epoch 367/500\n","12/12 [==============================] - 25s 2s/step - loss: 47.2429 - val_loss: 535.2277\n","Epoch 368/500\n","12/12 [==============================] - 25s 2s/step - loss: 36.9611 - val_loss: 639.4924\n","Epoch 369/500\n","12/12 [==============================] - 25s 2s/step - loss: 28.2659 - val_loss: 705.9404\n","Epoch 370/500\n","12/12 [==============================] - 26s 2s/step - loss: 19.7637 - val_loss: 540.8158\n","Epoch 371/500\n","12/12 [==============================] - 26s 2s/step - loss: 13.3976 - val_loss: 473.2584\n","Epoch 372/500\n","12/12 [==============================] - 25s 2s/step - loss: 9.6760 - val_loss: 534.8346\n","Epoch 373/500\n","12/12 [==============================] - 25s 2s/step - loss: 6.6715 - val_loss: 557.9570\n","Epoch 374/500\n","12/12 [==============================] - 25s 2s/step - loss: 5.5715 - val_loss: 544.4646\n","Epoch 375/500\n","12/12 [==============================] - 25s 2s/step - loss: 4.8720 - val_loss: 526.7902\n","Epoch 376/500\n","12/12 [==============================] - 25s 2s/step - loss: 4.3825 - val_loss: 542.2991\n","Epoch 377/500\n","12/12 [==============================] - 25s 2s/step - loss: 4.0866 - val_loss: 542.2803\n","Epoch 378/500\n","12/12 [==============================] - 25s 2s/step - loss: 3.7697 - val_loss: 543.7489\n","Epoch 379/500\n","12/12 [==============================] - 25s 2s/step - loss: 3.5585 - val_loss: 525.2274\n","Epoch 380/500\n","12/12 [==============================] - 25s 2s/step - loss: 3.4125 - val_loss: 542.7239\n","Epoch 381/500\n","12/12 [==============================] - 25s 2s/step - loss: 3.2971 - val_loss: 569.7125\n","Epoch 382/500\n","12/12 [==============================] - 25s 2s/step - loss: 3.1396 - val_loss: 571.1257\n","Epoch 383/500\n","12/12 [==============================] - 25s 2s/step - loss: 3.1239 - val_loss: 550.7215\n","Epoch 384/500\n","12/12 [==============================] - 25s 2s/step - loss: 3.0680 - val_loss: 549.8198\n","Epoch 385/500\n","12/12 [==============================] - 25s 2s/step - loss: 3.0516 - val_loss: 553.0917\n","Epoch 386/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.9852 - val_loss: 558.8466\n","Epoch 387/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.8926 - val_loss: 545.0248\n","Epoch 388/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.8085 - val_loss: 528.0213\n","Epoch 389/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.7970 - val_loss: 516.7764\n","Epoch 390/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.7941 - val_loss: 513.8890\n","Epoch 391/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.6853 - val_loss: 505.4064\n","Epoch 392/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.6537 - val_loss: 497.2310\n","Epoch 393/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.6014 - val_loss: 504.9437\n","Epoch 394/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.5783 - val_loss: 496.4039\n","Epoch 395/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.5357 - val_loss: 496.7669\n","Epoch 396/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.4502 - val_loss: 487.4189\n","Epoch 397/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.4796 - val_loss: 475.7230\n","Epoch 398/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.4944 - val_loss: 483.4090\n","Epoch 399/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.3933 - val_loss: 483.9971\n","Epoch 400/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.3658 - val_loss: 479.5196\n","Epoch 401/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.3220 - val_loss: 486.4996\n","Epoch 402/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.2941 - val_loss: 492.8611\n","Epoch 403/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.2665 - val_loss: 481.4911\n","Epoch 404/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.2457 - val_loss: 466.6068\n","Epoch 405/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.2363 - val_loss: 467.6645\n","Epoch 406/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.2434 - val_loss: 467.7234\n","Epoch 407/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.1879 - val_loss: 465.2376\n","Epoch 408/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.2419 - val_loss: 470.3767\n","Epoch 409/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.3042 - val_loss: 457.1126\n","Epoch 410/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.1216 - val_loss: 466.5714\n","Epoch 411/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.1493 - val_loss: 457.7713\n","Epoch 412/500\n","12/12 [==============================] - 25s 2s/step - loss: 1.9881 - val_loss: 447.8678\n","Epoch 413/500\n","12/12 [==============================] - 25s 2s/step - loss: 1.9848 - val_loss: 463.1540\n","Epoch 414/500\n","12/12 [==============================] - 25s 2s/step - loss: 1.8754 - val_loss: 481.0773\n","Epoch 415/500\n","12/12 [==============================] - 25s 2s/step - loss: 1.8575 - val_loss: 478.5790\n","Epoch 416/500\n","12/12 [==============================] - 25s 2s/step - loss: 1.8879 - val_loss: 480.7769\n","Epoch 417/500\n","12/12 [==============================] - 25s 2s/step - loss: 1.8457 - val_loss: 480.5934\n","Epoch 418/500\n","12/12 [==============================] - 25s 2s/step - loss: 1.8029 - val_loss: 474.8156\n","Epoch 419/500\n","12/12 [==============================] - 25s 2s/step - loss: 1.8124 - val_loss: 484.4629\n","Epoch 420/500\n","12/12 [==============================] - 25s 2s/step - loss: 1.6644 - val_loss: 468.2000\n","Epoch 421/500\n","12/12 [==============================] - 25s 2s/step - loss: 1.6037 - val_loss: 448.3146\n","Epoch 422/500\n","12/12 [==============================] - 25s 2s/step - loss: 1.5741 - val_loss: 452.4418\n","Epoch 423/500\n","12/12 [==============================] - 25s 2s/step - loss: 1.5910 - val_loss: 441.6708\n","Epoch 424/500\n","12/12 [==============================] - 25s 2s/step - loss: 1.5193 - val_loss: 441.0250\n","Epoch 425/500\n","12/12 [==============================] - 25s 2s/step - loss: 1.5850 - val_loss: 454.0633\n","Epoch 426/500\n","12/12 [==============================] - 25s 2s/step - loss: 1.5062 - val_loss: 477.2934\n","Epoch 427/500\n","12/12 [==============================] - 25s 2s/step - loss: 1.7197 - val_loss: 463.5504\n","Epoch 428/500\n","12/12 [==============================] - 25s 2s/step - loss: 1.5396 - val_loss: 483.0240\n","Epoch 429/500\n","12/12 [==============================] - 25s 2s/step - loss: 1.5152 - val_loss: 476.6453\n","Epoch 430/500\n","12/12 [==============================] - 25s 2s/step - loss: 1.5399 - val_loss: 486.1825\n","Epoch 431/500\n","12/12 [==============================] - 25s 2s/step - loss: 1.6005 - val_loss: 453.4826\n","Epoch 432/500\n","12/12 [==============================] - 25s 2s/step - loss: 1.5639 - val_loss: 431.4158\n","Epoch 433/500\n","12/12 [==============================] - 25s 2s/step - loss: 1.3416 - val_loss: 432.7840\n","Epoch 434/500\n","12/12 [==============================] - 25s 2s/step - loss: 1.4209 - val_loss: 447.9496\n","Epoch 435/500\n","12/12 [==============================] - 25s 2s/step - loss: 1.2411 - val_loss: 442.2493\n","Epoch 436/500\n","12/12 [==============================] - 25s 2s/step - loss: 1.1761 - val_loss: 410.8633\n","Epoch 437/500\n","12/12 [==============================] - 25s 2s/step - loss: 1.1328 - val_loss: 406.6274\n","Epoch 438/500\n","12/12 [==============================] - 25s 2s/step - loss: 1.3926 - val_loss: 408.6962\n","Epoch 439/500\n","12/12 [==============================] - 25s 2s/step - loss: 1.3928 - val_loss: 410.4794\n","Epoch 440/500\n","12/12 [==============================] - 25s 2s/step - loss: 1.2769 - val_loss: 431.9306\n","Epoch 441/500\n","12/12 [==============================] - 25s 2s/step - loss: 1.4038 - val_loss: 412.8551\n","Epoch 442/500\n","12/12 [==============================] - 25s 2s/step - loss: 1.3178 - val_loss: 406.7810\n","Epoch 443/500\n","12/12 [==============================] - 25s 2s/step - loss: 1.3617 - val_loss: 396.4093\n","Epoch 444/500\n","12/12 [==============================] - 25s 2s/step - loss: 1.2692 - val_loss: 396.8117\n","Epoch 445/500\n","12/12 [==============================] - 25s 2s/step - loss: 1.4512 - val_loss: 405.6830\n","Epoch 446/500\n","12/12 [==============================] - 25s 2s/step - loss: 1.6369 - val_loss: 387.6859\n","Epoch 447/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.2628 - val_loss: 368.7668\n","Epoch 448/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.4058 - val_loss: 407.7069\n","Epoch 449/500\n","12/12 [==============================] - 25s 2s/step - loss: 3.0519 - val_loss: 338.5196\n","Epoch 450/500\n","12/12 [==============================] - 25s 2s/step - loss: 3.9357 - val_loss: 330.4943\n","Epoch 451/500\n","12/12 [==============================] - 25s 2s/step - loss: 4.1017 - val_loss: 367.5214\n","Epoch 452/500\n","12/12 [==============================] - 25s 2s/step - loss: 4.4168 - val_loss: 364.4778\n","Epoch 453/500\n","12/12 [==============================] - 25s 2s/step - loss: 4.2499 - val_loss: 331.6433\n","Epoch 454/500\n","12/12 [==============================] - 25s 2s/step - loss: 4.4625 - val_loss: 350.0208\n","Epoch 455/500\n","12/12 [==============================] - 25s 2s/step - loss: 4.1643 - val_loss: 313.4232\n","Epoch 456/500\n","12/12 [==============================] - 25s 2s/step - loss: 3.5957 - val_loss: 317.8539\n","Epoch 457/500\n","12/12 [==============================] - 25s 2s/step - loss: 3.3983 - val_loss: 348.4801\n","Epoch 458/500\n","12/12 [==============================] - 25s 2s/step - loss: 4.1745 - val_loss: 302.3868\n","Epoch 459/500\n","12/12 [==============================] - 25s 2s/step - loss: 3.2984 - val_loss: 311.7242\n","Epoch 460/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.6630 - val_loss: 311.2987\n","Epoch 461/500\n","12/12 [==============================] - 25s 2s/step - loss: 2.4401 - val_loss: 307.9125\n","Epoch 462/500\n","12/12 [==============================] - 25s 2s/step - loss: 1.8807 - val_loss: 310.9181\n","Epoch 463/500\n","12/12 [==============================] - 25s 2s/step - loss: 1.8016 - val_loss: 320.6209\n","Epoch 464/500\n","12/12 [==============================] - 25s 2s/step - loss: 1.6811 - val_loss: 328.7597\n","Epoch 465/500\n","12/12 [==============================] - 25s 2s/step - loss: 1.4825 - val_loss: 333.7796\n","Epoch 466/500\n","12/12 [==============================] - 25s 2s/step - loss: 1.4155 - val_loss: 327.2683\n","Epoch 467/500\n","12/12 [==============================] - 25s 2s/step - loss: 1.3395 - val_loss: 325.2105\n","Epoch 468/500\n","12/12 [==============================] - 25s 2s/step - loss: 1.2616 - val_loss: 335.7541\n","Epoch 469/500\n","12/12 [==============================] - 25s 2s/step - loss: 1.1254 - val_loss: 354.5396\n","Epoch 470/500\n","12/12 [==============================] - 25s 2s/step - loss: 1.2850 - val_loss: 350.7516\n","Epoch 471/500\n","12/12 [==============================] - 25s 2s/step - loss: 1.2778 - val_loss: 350.7379\n","Epoch 472/500\n","12/12 [==============================] - 25s 2s/step - loss: 1.1457 - val_loss: 364.3789\n","Epoch 473/500\n","12/12 [==============================] - 25s 2s/step - loss: 1.0794 - val_loss: 373.6834\n","Epoch 474/500\n","12/12 [==============================] - 25s 2s/step - loss: 1.0209 - val_loss: 376.4871\n","Epoch 475/500\n","12/12 [==============================] - 25s 2s/step - loss: 0.9752 - val_loss: 381.3532\n","Epoch 476/500\n","12/12 [==============================] - 25s 2s/step - loss: 1.0108 - val_loss: 375.4692\n","Epoch 477/500\n","12/12 [==============================] - 25s 2s/step - loss: 0.9360 - val_loss: 368.7405\n","Epoch 478/500\n","12/12 [==============================] - 25s 2s/step - loss: 0.8883 - val_loss: 367.5135\n","Epoch 479/500\n","12/12 [==============================] - 26s 2s/step - loss: 0.8704 - val_loss: 366.3036\n","Epoch 480/500\n","12/12 [==============================] - 25s 2s/step - loss: 0.8533 - val_loss: 367.5426\n","Epoch 481/500\n","12/12 [==============================] - 25s 2s/step - loss: 0.8107 - val_loss: 365.4711\n","Epoch 482/500\n","12/12 [==============================] - 25s 2s/step - loss: 0.8269 - val_loss: 363.7082\n","Epoch 483/500\n","12/12 [==============================] - 25s 2s/step - loss: 0.7741 - val_loss: 365.8161\n","Epoch 484/500\n","12/12 [==============================] - 25s 2s/step - loss: 0.7580 - val_loss: 363.8811\n","Epoch 485/500\n","12/12 [==============================] - 25s 2s/step - loss: 0.7337 - val_loss: 363.3144\n","Epoch 486/500\n","12/12 [==============================] - 25s 2s/step - loss: 0.7481 - val_loss: 364.6875\n","Epoch 487/500\n","12/12 [==============================] - 25s 2s/step - loss: 0.7397 - val_loss: 371.9041\n","Epoch 488/500\n","12/12 [==============================] - 25s 2s/step - loss: 0.7345 - val_loss: 371.8089\n","Epoch 489/500\n","12/12 [==============================] - 25s 2s/step - loss: 0.7244 - val_loss: 368.7851\n","Epoch 490/500\n","12/12 [==============================] - 25s 2s/step - loss: 0.7241 - val_loss: 369.5483\n","Epoch 491/500\n","12/12 [==============================] - 25s 2s/step - loss: 0.7149 - val_loss: 370.4716\n","Epoch 492/500\n","12/12 [==============================] - 25s 2s/step - loss: 0.7197 - val_loss: 362.3571\n","Epoch 493/500\n","12/12 [==============================] - 26s 2s/step - loss: 0.7254 - val_loss: 360.4475\n","Epoch 494/500\n","12/12 [==============================] - 25s 2s/step - loss: 0.6772 - val_loss: 360.8260\n","Epoch 495/500\n","12/12 [==============================] - 25s 2s/step - loss: 0.6877 - val_loss: 356.8555\n","Epoch 496/500\n","12/12 [==============================] - 25s 2s/step - loss: 0.6546 - val_loss: 360.3415\n","Epoch 497/500\n","12/12 [==============================] - 26s 2s/step - loss: 0.6824 - val_loss: 367.0623\n","Epoch 498/500\n","12/12 [==============================] - 25s 2s/step - loss: 0.6834 - val_loss: 366.9250\n","Epoch 499/500\n","12/12 [==============================] - 25s 2s/step - loss: 0.7171 - val_loss: 365.2679\n","Epoch 500/500\n","12/12 [==============================] - 25s 2s/step - loss: 0.6748 - val_loss: 370.8308\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TE1OeIhAGFRj"},"source":["!mkdir -p saved_model\r\n","model.save('saved_model/nasnet')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KlHsiifdy5uv","colab":{"base_uri":"https://localhost:8080/","height":496},"executionInfo":{"status":"ok","timestamp":1615810813814,"user_tz":-360,"elapsed":16580,"user":{"displayName":"Townim Faisal Chowdhury","photoUrl":"","userId":"17782929784728513740"}},"outputId":"36c0649d-549f-4b86-c166-917d46581688"},"source":["# Get the prediction model by extracting layers till the output layer\r\n","prediction_model = keras.models.Model(\r\n","    model.get_layer(name=\"image\").input, model.get_layer(name=\"dense3\").output\r\n",")\r\n","prediction_model.summary()\r\n","\r\n","# A utility function to decode the output of the network\r\n","def decode_batch_predictions(pred):\r\n","    input_len = np.ones(pred.shape[0]) * pred.shape[1]\r\n","    # Use greedy search. For complex tasks, you can use beam search\r\n","    results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=False, beam_width=100)[0][0][\r\n","        :, :max_length\r\n","    ]\r\n","    # Iterate over the results and get back the text\r\n","    output_text = []\r\n","    for res in results:\r\n","        res = tf.strings.reduce_join(num_to_char(res)).numpy().decode(\"utf-8\")\r\n","        output_text.append(res)\r\n","    return output_text\r\n","\r\n","for batch in validation_dataset.take(1):\r\n","    batch_images = batch[\"image\"]\r\n","    batch_labels = batch[\"label\"]\r\n","\r\n","    preds = prediction_model.predict(batch_images)\r\n","    pred_texts = decode_batch_predictions(preds)\r\n","    print(pred_texts)\r\n","    for i in range(1):\r\n","        img = (batch_images[i] * 255).numpy().astype(\"uint8\")\r\n","        # print(img.shape) # (200, 50, 1)\r\n","        plt.imshow(img[:, :, 0].T, cmap=\"gray\")\r\n","        plt.axis(\"off\")\r\n","plt.show()"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","image (InputLayer)           [(None, 2452, 144, 3)]    0         \n","_________________________________________________________________\n","NASNet (Functional)          (None, 77, 5, 1056)       4269716   \n","_________________________________________________________________\n","reshape (Reshape)            (None, 385, 1056)         0         \n","_________________________________________________________________\n","dense5 (Dense)               (None, 385, 512)          541184    \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 385, 512)          0         \n","_________________________________________________________________\n","bidirectional_2 (Bidirection (None, 385, 512)          1574912   \n","_________________________________________________________________\n","bidirectional_3 (Bidirection (None, 385, 256)          656384    \n","_________________________________________________________________\n","dense3 (Dense)               (None, 385, 104)          26728     \n","=================================================================\n","Total params: 7,068,924\n","Trainable params: 7,032,186\n","Non-trainable params: 36,738\n","_________________________________________________________________\n","['যোসধনা সশ্ ুহরযা অয়ক ল্ব সত্যবারয়র ম্যা কট য বচডব বাবর -যোন[UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK]', 'মোহন বুজ্ত, অকা, অক্টি ক্ল কল দৰব ব্বপবা, , বঠর ব্াইর[UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK]', 'আহ কি িয়াসকতরে াু[UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK]', 'বিস্য কা্যার অ্া অর্া ক ্ত ভযা ্বলরদু ব়বভ বন্ব বাবাসতন[UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK]', 'হা্ ল । ।”।”[UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK]', 'হই, ক্মে়, এয়গে তে ও।সগ\"[UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK]', 'সর্মারডলের অঙ্গে সপে্টে কভেদ্া বে ক ্াদ ্ বাুাীরব্া মায়া অাব্র।\"[UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK]', 'বোখন দত্যা সেড়ে এেবি কা উি ।—ল[UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK]', '“অপ্য কান ক্তা া বু্টর ্বিায়ু বঞবাথ্ ি দাুাটু[UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK]', 'আা কযে পে়া একে কবো বতবলই লোঠ[UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK]', 'গোন্ প্যলের পন্যে করবযাকীর দাবাইিইওশাগি  ুও[UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK]', 'অহন নজিত কহকা অ্যনিল গ্দটা অদ-ব-্-ীমা বম্, বপডা।\"[UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK]', 'দারিও আিন কিে ভিত য্ু ্াহ বয়া বাতঃোিয়া াহান[UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK]', 'দেখন সরতি, কিরয় ক্াব্ু ত ই বাবাবরওাু বু ুানু[UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK]', 'মোহন তিল অোহ্যিত অত্যক্ল “্যাু ব্যব-া ব্বীর অব-্ব় ।[UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK]', 'চহে কোাে ছিলা লা া কং দাবা বরবাতবিরব্ডধ অর ব্য়া চ্া।[UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK]']\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"-gRufb3jy5uv","colab":{"base_uri":"https://localhost:8080/","height":598},"executionInfo":{"status":"ok","timestamp":1615458751432,"user_tz":-360,"elapsed":3530,"user":{"displayName":"Townim Faisal Chowdhury","photoUrl":"","userId":"17782929784728513740"}},"outputId":"a02f9a4a-f881-4993-b9ce-95901e837dc9"},"source":["test_datafile = open('./Data/ICBOCR-D4/custom-images/Groundtruth.txt', encoding='utf8')\r\n","test_lines = [line.rstrip() for line in test_datafile]\r\n","\r\n","test_image_dir = \"./Data/ICBOCR-D4/custom-images/Line_images/\"\r\n","test_image_paths = [os.path.join(test_image_dir, line.split('@')[0]) for line in test_lines]\r\n","test_captions = [line.split('@')[1].lstrip() for line in test_lines]\r\n","\r\n","\r\n","x_test, _, y_test, _ = split_data(np.array(test_image_paths), np.array(test_captions), train_size=1.0, shuffle=True)\r\n","\r\n","batch_size = 1\r\n","test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\r\n","test_dataset = test_dataset.map(\r\n","        encode_single_sample, num_parallel_calls=tf.data.experimental.AUTOTUNE\r\n","    ).batch(batch_size)#.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\r\n","\r\n","# Get the prediction model by extracting layers till the output layer\r\n","prediction_model = keras.models.Model(\r\n","    model.get_layer(name=\"image\").input, model.get_layer(name=\"dense2\").output\r\n",")\r\n","prediction_model.summary()\r\n","\r\n","# A utility function to decode the output of the network\r\n","def decode_batch_predictions(pred):\r\n","    input_len = np.ones(pred.shape[0]) * pred.shape[1]\r\n","    # Use greedy search. For complex tasks, you can use beam search\r\n","    results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=False, beam_width=100)[0][0][\r\n","        :, :max_length\r\n","    ]\r\n","    # Iterate over the results and get back the text\r\n","    output_text = []\r\n","    for res in results:\r\n","        res = tf.strings.reduce_join(num_to_char(res)).numpy().decode(\"utf-8\")\r\n","        output_text.append(res)\r\n","    return output_text\r\n","\r\n","for batch in test_dataset.take(1):\r\n","    batch_images = batch[\"image\"]\r\n","    batch_labels = batch[\"label\"]\r\n","\r\n","    preds = prediction_model.predict(batch_images)\r\n","    pred_texts = decode_batch_predictions(preds)\r\n","    print(pred_texts)\r\n","    for i in range(1):\r\n","        img = (batch_images[i] * 255).numpy().astype(\"uint8\")\r\n","        # print(img.shape) # (200, 50, 1)\r\n","        plt.imshow(img[:, :, 0].T, cmap=\"gray\")\r\n","        plt.axis(\"off\")\r\n","plt.show()\r\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","image (InputLayer)           [(None, 2452, 144, 1)]    0         \n","_________________________________________________________________\n","Conv1 (Conv2D)               (None, 2452, 144, 32)     320       \n","_________________________________________________________________\n","pool1 (MaxPooling2D)         (None, 1226, 72, 32)      0         \n","_________________________________________________________________\n","Conv2 (Conv2D)               (None, 1226, 72, 64)      18496     \n","_________________________________________________________________\n","pool2 (MaxPooling2D)         (None, 613, 36, 64)       0         \n","_________________________________________________________________\n","reshape (Reshape)            (None, 613, 2304)         0         \n","_________________________________________________________________\n","dense1 (Dense)               (None, 613, 512)          1180160   \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 613, 512)          0         \n","_________________________________________________________________\n","bidirectional_2 (Bidirection (None, 613, 1024)         4198400   \n","_________________________________________________________________\n","bidirectional_3 (Bidirection (None, 613, 1024)         6295552   \n","_________________________________________________________________\n","dense2 (Dense)               (None, 613, 103)          105575    \n","=================================================================\n","Total params: 11,798,503\n","Trainable params: 11,798,503\n","Non-trainable params: 0\n","_________________________________________________________________\n","['খন\"[UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK]']\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"Pte4vaRCy5uv"},"source":[""],"execution_count":null,"outputs":[]}]}